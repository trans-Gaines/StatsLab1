---
title: "Lab 3"
output: html_document
---
**1. Create five samples of 25 observations from a normal distribution with mean 200, and standard deviation 100. Compute the mean of each sample, and plot the means in a graph using ggplot2. (1 point)**

We use a for loop to do one action 5 times. In this context, our action is to sample (25 times) from a normal distribtuion with a particular shape (mean 200, SD 100) and compute the mean of that sample. 

We learn how to do the action once.

```{r}
single_sample <- rnorm(n= 25,mean = 200, sd = 100)
mean(single_sample)
```
I then attempted to use for loops to do this action five times and store them into one variable ("Multi_Sample") however trying multiple ways, I was not successful in getting the action to be performed afresh. Instead I think it was overwriting the next value into a single spot within Multi_Sample.

Example:
```{r}
for(i in 1:5){
Multi_Sample <- data.frame(mean(rnorm(n= 25,mean = 200, sd = 100)),
                      sample = 5)}
print.data.frame(Multi_Sample)
```

So I used Professor Crump's method:
```{r}
observations <- rnorm(5*25, mean=200, sd=100)
samples <- rep(1:5, each =25)
my_dataframe <- data.frame(samples,observations)
library(dplyr)
means <- my_dataframe %>%
  group_by(samples) %>%
  summarize(sample_mean = mean(observations))
library(ggplot2)

ggplot(means, aes(x = samples, y =sample_mean))+
         geom_histogram(stat="identity")
```

*Self Assessment: 30*

**Additionally calculate the standard deviation of each sample from above. Use the standard deviations for error bars, and produce another graph with the means along with error bars using ggplot2. (1 point)**


```{r}
observations <- rnorm(5*25, mean=200, sd=100)
samples <- rep(1:5, each =25)
my_dataframe <- data.frame(samples,observations)
library(dplyr)
means <- my_dataframe %>%
  group_by(samples) %>%
  summarize(sample_mean = mean(observations),
            sample_sd = sd(observations))

      
ggplot(means, aes(x = samples, y =sample_mean))+
         geom_histogram(stat="identity") + 
        geom_errorbar(aes(ymin = sample_mean- sample_sd,
                          ymax = sample_mean + sample_sd),
                        width = .5)
                    
                      

```

*Self Assessment: 70*

**3. Demonstrate that the sample mean across a range of n, is an unbiased estimator of the population mean using a monte-carlo simulation. (2 points).
The population is a normal distribution with mean = 10, standard deviation = 5. Test a variety of n (sample size), including n = 2, 5, 10, 50, and 100**

We first ensure that we can do the basic sampling
```{r}
rnorm(2, mean = 10, sd = 5)
```

*For each sample size n, your task is to draw 10,000 samples of that size, then for each sample, calculate the sample mean.*
```{r}
observations <- rnorm(2*10000, mean = 10, sd = 5)
samples <- rep(1:10000, each =2)
My_data <- data.frame(samples,observations)
##create our spreadsheet of these samples
means <- My_data %>%
  group_by(samples) %>%
  summarize(sample_mean = mean(observations))
```

**If the mean is unbiased, then we expect that “on average” the sample means will be the same as the population mean. To determine if this is true, compute the mean of the sample means that you produce to see if it is close to the population mean.**

```{r}
observations <- rnorm(2*10000, mean = 10, sd = 5)
samples <- rep(1:10000, each =2)
My_data <- data.frame(samples,observations)

means <- My_data %>%
  group_by(samples) %>%
  summarise(sample_mean = mean(observations))
##Find mean of the mean column
mean(mean(observations))
```
Fairly close.
**Show the mean of the sample means for each sample size.**

We create a for loop.  In this example, Professor Crump models what I had missed above, which was creating a dataframe to hold two corresponding columns. I could not get the summarized_data$ function from the generalization video to work in my code, so I performed a workaround.

```{r}
samples_sizes <- c(2,5,10,50,100)
for(n in samples_sizes){
  observations <- rnorm(n*10000, mean = 10, sd = 5)
samples <- rep(1:10000, each = n)
My_data <- data.frame(samples,observations)

means <- My_data %>%
  group_by(samples) %>%
  summarize(sample_means = mean(observations))

print(mean(mean(observations)))
}

```


*Self Assesment: 40*

**4. Use a monte carlo simulation to compare the standard deviation formulas (divide by N vs N-1), and show that the N-1 formula is a better unbiased estimate of the population standard deviation, especially for small n. (2 points) Use the same normal distribution and samples sizes from above
Rather than computing the mean for each sample, compute both forms of the standard deviation formula, including the sample standard deviation that divides by N-1, and the regular standard deviation that divides by N. You should have 10,000 samples for each sample size, and 10,000 standard deviations for each the sample and regular standard deviation. Your task is to find the average of each, for each sample-size.**

We first define our standard deviation formulas:

```{r}
###SD For population rather that sample
SDPopulation <- function(x){
    sqrt(sum((mean(x)-x)^2) / length(x))}
###SD for sample
SDSample <- function(x){
   sqrt( sum((mean(x)-x)^2) / (length(x)-1))
  }

```
We then build the Monte Carlo simulation for a population:
```{r}

print("These are the Population (n in Denominator) Standard Deviations")
samples_sizes <- c(2,5,10,50,100)
for(n in samples_sizes){
  observationsSD <- rnorm(n*10000, mean = 10, sd = 5)
samplesSD <- rep(1:10000, each = n)
My_dataSD <- data.frame(samplesSD, observationsSD)

sumarized_Date <- My_dataSD %>%
  group_by(samplesSD) %>%
  summarize(sample_meansSD = mean(observationsSD))

print(SDPopulation(observationsSD))
}
```
We then build the Monte Carlo simulation for a sample:
```{r}
print("These are the Sample (n-1 in Denominator) Standard Deviations")
samples_sizes <- c(2,5,10,50,100)
for(n in samples_sizes){
  observationsSD <- rnorm(n*10000, mean = 10, sd = 5)
samplesSD <- rep(1:10000, each = n)
My_dataSD <- data.frame(samplesSD, observationsSD)

sumarized_Date <- My_dataSD %>%
  group_by(samplesSD) %>%
  summarize(sample_meansSD = mean(observationsSD))


print(SDSample(observationsSD))
}
```

*Self Assessment: 90*

**Which of the standard deviations is more systematically biased? That is, which one is systematically worse at estimating the population standard deviation?**

We know from clase that sample standard deviation corrects for degrees of freedom. In each case of the simulation we created above, we have provided an standard deviation, so we can calculate the mean difference of the observed standard deviation from the provided standard deviation and demonstrate this experimentally. In each case it should get better (closer to provided SD) as the sample size increases, so we can compare each one to the given SD (5) and see which wins (math below). We see sample "wins" by being closer 4/5 times, only losing the sample size of 2, which is expected to be the most varying in general. Population standard deviation is worse at estimating population standard deviation.

Sample size 2:
Population=[5-5.034673]
Population=0.034673
Sample=[5-4.960082]
Sample=.039918
Population<Sample, population wins

Sample Size 5:
Population=[5-4.978071]
Population=.021929
Sample=[5-4.993785]
Sample=.006215
Sample<Population, sample wins

Sample Size 10
Population=[5-5.005426]
Population=0.005426
Sample=[5-5.004]
Sample= 0.004
Sample<Population, sample wins

Sample Size 50:
Population=[5-4.995117]
Population=0.004883
Sample=[5-4.998141]
Sample= 0.001859
Sample<Population, sample wins

Sample Size 100:
Population=[5-4.995733]
Population=0.004267
Sample=[5-4.999876]
Sample= 0.000124
Sample<Population, sample wins

*Self Assessment: 100*
